---
layout: post
title:  "LeNet"
date:   2018-06-27 13:47:35 +0900
categories: ComputerVision
tag: CNN
---


#### LeNet

CNN 모델을 최초로 개발한 사람은 프랑스 출신의 Yann LeCun이며, 1989년 *"Backpropagation applied to handwritten zip code recognition"* 논문을 통해 최초로 CNN을 사용하였고, 이후 1998년 LeNet이라는 Network를 소개하였다.  

LeNet은 우편번호와 수표의 필기체를 인식하기 위해 개발되었다. LeNet의 최종 모델인 LeNet5의 Architecture를 보면 아래와 같이 이루어져
![LeNet5](http://nocotan.github.io/images/20170804/lenet.png)

LeNet 5는 총 7개의 Layer로 구성되어 있다. 두개의 Convolution Layer, 2개의 Sub-Sampling Layer, 2개의 Fully-Connected Layer 그리고 최종 출력 Layer로 이루어져 있다.

* 1-layer : Convolution Layer
Input Data(32x32, 1개의 Channel)를 5x5 Filter 6개를 사용해 Convolution한다. 그결과로는 28x28 사이즈의 Feature map을 6개 만들어 낸다. Parameter의 수는 아래와 같다.
5x5 filter 6개, bias 6개 => $5*5*6+1*6=156$

* 2-layer : SubSampling Layer
28x28의 feature map에 대해 2x2size의 receptive field로 Average Pooling을 시행한다. 따라서 14x14 size를 6개 만든다.

* 3-layer : Convolution layer2
Conv layer1과 동일하게 5x5 Filter 16개를 사용해 총 10x10 feature map 16개를 만들어 낸다. 일반적으로 수행한다면 6x16 인 96개의 feature map이 만들어져야 하지만 여기서는 모든 map을 연결 하는 것이 아니라 아래의 Table과 같이 선택적으로 연결시켜 network의 symmetry한 성질을 없애려는 것으로 볼 수 있다. 최종적으로 Global feature를 얻기 위함이다.  
파라미터 수는 $5*5*60+1*16=1,516$개다.
![3-layer](http://img1.daumcdn.net/thumb/R1920x0/?fname=http%3A%2F%2Fcfile23.uf.tistory.com%2Fimage%2F99BE20385AA60C52242B82)

* 4-layer : SubSampling layer2
subsmapling1 layer와 마찬가지로 2x2 receptive field에 대해서 average polling을 시행한다.

* 5-layer : FC layer
5x5 filter 120개를 사용해 1x1 feature map 120개를 만든다
파라미터의 수는 $5*5*1920+1*120$개가 된다.

* 6-layer : FC layer2
1x1x120 date를 1x1x84개의 data로 만든다.
파라미터 수는 $120x84+1*84$개 이다.

* 7-layer :
