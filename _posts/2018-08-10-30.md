---
layout: post
title:  "Chapter 2: Function Approximation as Supervised Learning"
date:   2018-08-10 13:47:35 +0900
categories: Lecture
tag: NLP
---

### Chapter 2

### Function Approximation as Supervised Learning

이 내용은 Newyork University의 조경현교수님의 DS-GA 3001강의 lecture note중 Neural Laguage Models단원을 정리한 내용입니다.

---

이번 챕터에서는 인공 신경망을 통해 Natural Language를 함수로 근사시킬 것이다. 이러한 과정은 기본적인 신경망을 공부하는데 도움이 될 것이며, 다음 챕터부터의 공부에 용이하게 할 것이다.

### 2.1 Function Approximation: Parametrix Approache

#### 2.1.1 Expected Cost Function

가장 먼저 데이터 분포를 $$p_{\text{data}}$$로 정의한다. 각 데이터는 input 벡터인 $$\mathbf{x}\in\mathbb{I}^d$$와 output 벡터인 $$\mathbf{y}\in\mathbb{O}^d$$로 정의한다. $$\mathbb{I,O}$$는 input과 output으로 가능한 실수 값의 집합이다.

이제 우리의 목표는 $$\mathbf{x}$$ 와 $$\mathbf{y}$$ 사이의 관계를 찾는 것이다. 정확히는 두 집합사이의 함수 $$f:\mathbb{R}^d\rightarrow\mathbb{O}^k$$를 찾는 것이다. 최대한 정확한 $$f$$를 찾기 위해 함수를 parametric function을 고려한다. 여기서 파라미터는 $$\theta$$라 칭한다.

이제 우리가 근사한 함수가 얼마나 정확히 input에서 output으로 가기위해 확인하기 위해 우리가 예측한 값에 대해 정의한다.

$$
\hat{\mathbf{y}}=f_{\theta}(\mathbf{x})
$$

이제 우리가 정의한 함수의 정확도는 위의 값과 output과의 차이($$D(\hat{\mathbf{y}},\mathbf{y})$$)를 비교하면 될것이다. 그리고 최종적으로 해야 할 것은 이 차이를 최소화하는 파라미터 $$\theta$$를 찾으면 된다. 하지만 input과 output은 여러 쌍이 존재하는데 정확히 이 모든 쌍에 대해서 이 차이를 최소화하는 파라미터는 존재하기 어렵다. 따라서 전체 쌍에 대해서 차이의 총합을 최소화 하는 방향으로 가야한다. 이를 수식으로 표현하면 다음과 같다.

$$
\arg\min_{\theta}\int_{\mathbf{x}}\int_{\mathbf{y}}p_{\text{data}}(\mathbf{x},\mathbf{y})D(\hat{\mathbf{y}},\mathbf{y})d\mathbf{x}d\mathbf{y}
$$

만약 각 데이터들이 discrete하다면 적분 대신 $$\sum$$을 이용하면 된다. 이제 우리는 최소화 해야 하는 이 값을 Cost Function이라 부를 것이다. 그리고 이 값을 계산하는 것은 distance의 평균(기대값)을 계산하는 것과 같다.

$$
\begin{align*}
C(\theta)&=\int_{\mathbf{x}}\int_{\mathbf{y}}p_{\text{data}}(\mathbf{x},\mathbf{y})D(\hat{\mathbf{y}},\mathbf{y})d\mathbf{x}d\mathbf{y}
&=\mathbb{E}_{\mathbf{x},\mathbf{y}\~p_{\text{data}}}[D(\hat{\mathbf{y}},\mathbf{y})]
\end{align*}
$$

이 값을 cost 말고 또 loss 혹은 risk 라고도 부른다.

아쉽게도 이 값을 정확하게 계산하는 것은 불가능하다. 애초에 data의 정확한 distribution을 알지 못하고 안다고 해도 정확히 cost를 계산하는 것은 과한 가정을 필요로한다.

#### 2.1.2 Empirical Cost Function

우리가 정확한 data의 분포를 모른다고 하더라도 일정 크기의 data는 우리에게 주어진다. 따라서 sampleling의 가정을 통해 정확한 cost를 근사하는 값을 구할 수 있다.

$$
C(\theta)\approx\tilde{C}(\theta)=\frac{1}{N}\sum^N_{n=1}D(\hat{\mathbf{y}^n},\mathbf{y}^n)
$$

이 값을 empirical cost function이라 부른다. 이 값은 계산이 쉽기 때문에 이 값을 사용할 것이다. 하지만 후에 우리의 최종 목표는 정확한 expected Cost를 계산하는 것이다.

### 2.2 Learning as Optimization

앞서 설명한 Cost값을 가장 최소로하는 파라미터들을 찾아가는 과정을 *학습한다* 라고 표현한다. 기계에서 학습 데이터를 통해 최적의 함수를 찾도록 하는 것이다. 그리고 이 학습하는 과정을 최적화(optimization)이라고도 한다.

#### 2.2.1 Gradient-based Local Iterative Optimization

최적화 알고리즘은 다양하다. 때로는 closed한 형태의 최적화 파라미터를 찾을 수 있지만 보통의 경우에는 반복적으로 최적화 알고리즘을 수행하면서 최적의 파라미터 값을 찾아가야 한다.

여기서 말하는 반복적 최적화 알고리즘이란 조금씩 파라미터들을 수정하면서 최적의 Cost function, 즉 cost function의 최소값으로 수렴하는 것을 의미한다. 대부분의 파라미터 공간은 지역적이라 전체 공간을 측정할 필요가 없다.

가장 간단한 지역적 반복 최적화 알고리즘 중 하나는 경사하강법(Gradient Discent, GD) 알고리즘이다. 이름에서 나와있듯이 이 알고리즘은 Cost 함수의 미분값(gradient)에 의해 수행된다.

Cost 함수의 미분값인 $$\nabla\tilde{C}$$ 는 현재 파라미터 값에 대해서 값을 올리는 방향에 대한 벡터값을 갖는다. 따라서 이 벡터값의 반대방향으로 파라미터를 이동시키면 Cost함수가 적어지는 방향으로 이동한다. 아래 그림은 이러한 과정을 나타낸다.

![GD](https://i.imgur.com/lOFnCBF.jpg)

이 알고리즘에서 중요한 점은 우리가 찾은 방향에 대해서 얼마나 움직일 것인가 이다. 만약 너무 많이 움직인 다면 우리가 가야하는 최적의 값을 지나칠 수 있고 너무 조금 움직인다면 최적의 값으로 가기까지가 너무 오래걸린다. 여기서 말한 얼마나 움직일것인가를 나타내는 값은 $$\eta$$로 쓰고 학습률(learning rate)라 표현한다. 이 값은 우리가 정해줘야하는 파라미터 값이므로 GD 알고리즘의 hyperparameter이다.

학습률을 고려한 정확한 경사하강법 알고리즘에서 파라미터를 재정의(update)하는 방법을 정의하면 다음과 같다.

$$
\theta \leftarrow \theta-\eta\nabla\tilde{C}(\theta)
$$

위의 update는 우리가 정의한 횟수만큼 반복된 후에 그만한다.

#### 2.2.2 Stochastic Gradient Descent

GD알고리즘은 간단하지만 매우 잘 동작한다. 그리고 이 알고리즘은 앞으로 나올 좀 더 향상된 알고리즘들의 기본 개념이 된다. 좀더 향상된 방법들을 배우기 이전에 GD알고리즘에 대해서 좀더 논의해본다. GD알고리즘에는 약간의 문제점이 있다. 바로 $$\tilde{C}$$을 계산하는 것이 매우 많은 연산을 필요로 한다는 것이다. 데티어가 많아질 수록 연산은 더욱 많아지는데, 그 이유는 앞서 본것처럼 Cost를 계산할 때 우리는 모든 data에 대해서 Cost를 계산한 뒤 모든 값들을 평균한 값을 최종 Cost로 사용한다. 따라서 모든 많은 데이터에 대해서 Cost를 모두 계산해야 하는데 이러한 과정을 반복하기에는 연산량이 매우 많다.  

이러한 연산량이 많다는 문제점을 해결하기 위한 알고리즘이 Stochastic gradient descent(SGD)이다.

알고리즘을 설명하기에 앞서 설명한 Cost 함수를 정의를 다시 살펴보자.

$$
C(\theta)\approx\tilde{C}(\theta)=\frac{1}{N}\sum^N_{n=1}D(\hat{\mathbf{y}^n},\mathbf{y}^n)
$$

위 식을 보면 Cost 함수의 sum이 모든 데이터인 $N$에 대해서 계산된다. SGD 알고리즘에서는 이 값을 모두 계산하는 것이 아니라 $\mu<N$인 $\mu$개의 데이터에 대해서만 Cost를 계산해 평균한다. 따라서 아래의 식으로 다시 정의된다.

$$
C(\theta)\approx\tilde{C}_{\mu}(\theta)=\frac{1}{\mu}\sum^\mu_{n=1}D(\hat{\mathbf{y}^n},\mathbf{y}^n)
$$

따라서 전체 데이터에 대해서 계산하는 일반적인 Cost와는 달리 적은 수에 대해서 Cost를 계산하므로 계산량이 매우 줄어들 것이다. 그리고 계산한 cost에 대해서 앞서 말한 파라미터 업데이트 방법으로 업데이트 하면된다.

여기서 $\mu$는 사용자가 직접 지정하면 되고, 극단적으로 1로 지정해도 된다. 놀랍게도 이미 1951년에 이 방법이 최적값에 수렴한다는 것이 증명 되었다.

### 2.3 When do we stop learning?

이제부터는 우리는 SGD방법을 통해 최적의 함수 $$f$$를 찾아간다고 하자. 즉 데이터를 조금씩 적용시키면서 학습한다. 이때까지 학습하는 과정에서의 몇 가지 문제점들에 대해서 살펴봤다. 또 하나의 중요한 문제점이 있는데, 우리는 expectec cost function 함수를 사용할 수 없다는 점이다. 그 대신 우리는 empirical cost 함수를 사용한다고 해서 expected cost 함수에 근사시킨다고 했었다. 그런데 왜 이러한 점이 문제점일까? 왜냐하면 우리는 우리가 찾은 empirical cost함수의 minimum값이 expected cost function의 minimum값인지 알 수 없다. 아래의 그림을 보면 두 함수의 최소값이 다른 예를 볼 수 있다.

![mini](https://i.imgur.com/V7fywvZ.jpg)


#### 2.3.1 Early Stopping

그렇다면 우리는 어떻게 해야 하는가? 이러한 문제는 여러가지 방법이 있다. 그 중 하나인 반복적 최적화 방법에서 사용되는 early stopping에 대해서 소개한다.

early stopping을 사용하기위해 우선 데이터를 $$D_{\text{train}}$$과 $$D_{\text{validate}}$$ 두 부분으로 나눈다. 이 두개의 부분 데이터셋을 학습 데이터(training set), 검증 데이터(validation set)이라 부른다. 이제 학습 cost를 다음과 같이 정의한다.

$$
\tilde{C}(\theta)=C_{\text{train}}(\theta)=\frac{1}{\vert D_{\text{train}}\vert}\sum_{(x,y)\in D_{\text{train}}}D(\hat{y},y)
$$  

그리고 검증 cost는 다음과 같이 정의한다.

$$
\tilde{C}(\theta)=C_{\text{val}}(\theta)=\frac{1}{\vert D_{\text{val}}\vert}\sum_{(x,y)\in D_{\text{val}}}D(\hat{y},y)
$$  

이렇게 두개의 cost 함수를 정의하면 early stopping을 사용할 준비가 끝났다.

학습 Cost로 SGD를 사용해서 parameter를 업데이트 할 때마다 검증 Cost를 계산한다. 이러한 과정을 계속 반복하다가 검증 Cost가 줄어들지 않을 때 그 때 반복을 멈춘다.

매우 간단한 방법임에도 불구하고 early stopping 은 매우 효율적이다. 이 방법은 사실상 deep learning과 machine learning 분야에서 표준이 되었다.

이러한 방법, 즉 학습과 검증을 구분한 것의 의미는 학습 데이터에 섞인 노이즈에 의한 학습이 제대로 되지 않는 것을 줄이는 것이다.

#### 2.3.2 Model Selection

검증 데이터를 early stopping에서 활용하는 것에 대해서 알아봤다. ealry stopping 뿐만 아니라 Model Selection 에서도 검증 데이터를 활용한다. 그렇다면 Model selection이 무었인지 알아보도록하자.

전체 최적화, 학습 과정은 전체 hypothesis(가정) space에서 최적의 hypothesis을 찾아가는 과정으로 표현할 수 있다. 여기서 말하는 hypothesis가 의미하는 것은 특정한 파라미터와 특정한 형태를 가지는 함수이다. 회귀(regression)의 경우에 hypothesis space에는 n차 다항식 함수가 포함될 것이다.

$$
f(x)=\sum_{\sum^d_{k=1}i_k=n,i_k\ge0}a_{i_1,i_2,...,i_k}\prod^d_{k'=1}x_{k'}^{i_k}
$$

신경망의 경우에는 이러한 hypothesis space는 모든 가능한 모델을 포함할 것이다. 그리고 각각의 hypothesis는 레이어의 수, 비선형성의 종류, hidden unit의 개수에서 특정 값을 가질 것이다.

우리가 특정 hypothesis($$M\in H$$)를 사용한다고 하자. 우리는 각각의 hypothesis에 대해서 각각의 Cost를 점수로 줄 수 있다. 그러면 이제 우리의 최종 목표는 전체적으로 최저의 cost값을 갖는 hypothesis를 선택하는 것이다.

이때까지의 최적화 방법은 반복적으로 empirical cost를 계산하는 것이다. 그러나 이러한 방법은 모델이 overfitting 될 수 있다는 문제점이 있다. 따라서 앞서서 early stopping이라는 기법을 소개했었다.

하지만 이러한 방법으로도 최적의 hypothesis를 찾는 것에는 충분하지는 않다. 우리가 최적이라고 생각하는 hypothesis가 최적이 아닐 수도 있다는 문제점이 항상 존재한다.

이러한 문제의 해결책은 간단하다. 하나 이상의 hypothesis를 고려하는 것이다. 예를들어 회귀문제에 대해서 우리는 linear 함수, quadratic 함수, sinusoidal 함수 모두를 hypothesis로 고려할 수 있다. 이제 마지막 남은 질문은 어떻게 이 hypothesis들을 비교하고 선택해야 하는가 이다.

early sotpping에서 했던 것과 비슷하게 우리는 검증 cost를 이용해 hypothesis들을 비교한다. 우리가 고려한 hypothesis들 중에서 가장 적은 검증 cost 값을 가지는 hypothesis를 선택하면 된다.

### 2.4 Evaluation

우리는 검증 cost를 통해서 최적화를 early stop했다. 이렇게 찾은 값이 최적화를 위한 값임에는 틀림없지만 실제 세계의 데이터 분포에도 완벽히 최적화된 값이라고 하기에는 어려움이 있다. 일단 최적화가 완료되어도 아직 우리는 더많은 검증을 위한 자료들이 필요하다.

따라서 우리는 데이터를 앞전처럼 두 개로 나누는 것이 아니라 이번에는 세 개로 나눈다. 학습 데이터인 $$D_{\text{train}}$$, 검증 데이터 $$D_{\text{validation}}$$, 그리고 시험(test) 데이터
$$D_{\text{test}}$$. 결과적으로 우리는 학습, 검증, 시험의 총 3개의 cost를 가진다. 여기서 추가로 나눈 시험(test) 데이터는 학습, 검증 데이터를 모두 사용해 최적이라고 선택한 모델에 대해서 시험한다. 테스트 데이터에 대해서 가장 중요한 말이 하나있다. "must never look at a test set", 즉 test 데이터는 최종적으로 test하기 이전에는 절대 건들면 안된다는 뜻이다.

### 2.5 Linear Regression for Non-Linear Functions

간단한 linear 함수를 생각해보자.

$$
\hat{\mathbf{y}}=f(\mathbf{x})=\mathbf{W}^T\mathbf{x}
$$

여기서 $$\mathbf{W}\in\mathbf{R}^{d\times l}$$는 weight matrix로 이 함수의 파라미터가 된다.

이 때 empirical cost 함수는 다음과 같다.

$$
\tilde{C}(\theta)=\frac{1}{N}\sum^N_{n=1}\frac{1}{2}\Vert\mathbf{y}^n-\mathbf{W}^T\mathbf{x}^n\Vert^2_2
$$

그리고 이 empirical cost함수의 gradient는 다음과 같다.

$$
\nabla\tilde{C}(\theta)=-\frac{1}{N}\sum^N_{n=1}(\mathbf{y}^n-\mathbf{W}^T\mathbf{x}^n)^T\mathbf{x}^n
$$

위 함수들을 통해 우리는 SGD, GD와 반복적 최적화 알고리즘을 적용시킬 수 있다. 이 알고리즘을 통해 최적의 파라미터 $$\mathbf{W}$$를 찾을 수 있고 또 검증 데이터를 사용해서 early stopping을 사용한다면 더 최적화된 파리미터를 찾을 수 있다.
하지만 이런 linear 함수는 우리가 만족기에는 부족하다.

#### 2.5.1 Feature Extraction

왜 우리는 만족하지 못할까?

첫 째로, 일단 모든 데이터에 맞는 함수가 linear라고 확신 할 수 없다. 만약 맞다고 하더라도 정확하게 linaer regression을 하는 것도 쉽지 않다.

두 번째 이유는 주어진 데이터 $$\mathbf{x}$$에 대해서 어떻게 이 값을 input으로 표현하는지에 대해서 확실한 방법이 없다는 것이다. 예를 들어 5년 전에 판매를 시작한 에어컨의 예상 판매 대수를 예측하는 문제를 생각해보자. 이 때 input을 판매를 시작한 때부터의 기간이라고 가정하고 output을 하루당 판매 대수라고 생각하자.

명백하게 우선 input과 output은 선형관계가 아닐 것이다. 계절에 따라 판매량을 등락을 반복할 것이고 따라서 단순히 직선으로는 표현할 수 없다. 그러나 만약에 input을 위와 같이 판매를 시작한 때부터의 기간이 아니라 6월을 기준으로 몇월 차이가 나는지로 한다고 하자. 예를 들면 8월이면 input은 2가 되고 3월이면 input은 3이 된다. 이러한 경우에는 직관적으로도 input과 output은 선형을 만족할 것이라는 것을 알 수 있다.

즉 여기서 말하는 바는 input 값을 어떻게 표현하냐가 매우 중요하게 작용할 수 있다는 것이다. 이러한 input을 표현하는 과정을 Feature Extraction(특징 추출)이라고 표현한다.

이러한 특징 추출은 우리가 해결할 문제의 영역에 대한 깊은 이해를 필요로한다.
