---
layout: post
title:  "End to End Memory Network"
date:   2018-10-07 18:47:35 +0900
categories: NLP
tag: NLP
---


지난 포스트인 [Memory Network](https://arxiv.org/pdf/1410.3916.pdf)에 이어 다음 논문으로 볼 수 있는 [End to End Memory Network](https://arxiv.org/pdf/1503.08895.pdf) 논문을 소개한다. 기존의 Memory Network의 경우 모델의 전 과정이 supervised 하기 떄문에 일반적으로 사용하기 어렵고 제약된 사항이 많았으나, 해당 논문의 경우 이름을 보면 알 수 있듯 End to End 한 모델을 제시해서 사용하기 쉽도록 구성되어있다. 이전 논문을 읽지 않았다면 읽은 후에 이 글을 읽도록 하자.

1. [Memory Network](https://reniew.github.io/45)
2. [End-to-End Memory Network](https://reniew.github.io/46)[현재글]

---

#### Introduction

최근 모델에서 attention의 개념과 부가적인 storage를 도입함으로써 모델의 성능을 향상시켰다. "Memory Network", "Neural machine translation by jointly learning to align and translate", "Neural turing machines" 에서 소개된 모델을을 보면 continuous한 representation을 저장하는 저장소를 따로 사용하고 있다. 그리고 이 값들을 읽고 모델의 일부분으로 사용을 한다.

해당 논문에서는 continuous한 형태의 Memory Network 모델을 소개한다. 기존의 memory network의 경우 backpropagation을 통해 학습이 어려웠고, 각 component, 즉 각 layer에서 supervised 하기 때문에 제약이 있었다는 단점이 있다. 이러한 문제를 해결하기 위해 end to end로 학습할 수 있는 모델을 제시한다. 따라서 이 모델은 기존의 모델보다 unsupervised한 성격의 모델로 제약없이 많은 task에 적용할 수 있을 것이다.

#### Approach

모델에서 input 값으로 discrete 한 값인 $x_1, x_2,...,x_n$를 받는다. 이 값들은 하나를 제외한 전부는 memory로 저장될 것이고 하나는 질문(query) $q$이다. 그리고 output은 이 질문에 대한 대답인 $a$가 나온다. memory $x_i$, query $q$, answer $a$ 는 모두 $V$개의 단어들의 dictionary들의 값들로 구성된다. input 값들은 multiple hop 구조를 통해 continuous한 output인 $a$ 값을 만든다. 이러한 구조는 backpropagation을 통해 학습이 쉽도록 만든다. 모델의 전체적인 구조는 아래의 그림과 같다.

![end2end](https://i.imgur.com/Ff2G9Qm.jpg)

위의 그림의 (a)인 왼쪽 그림은 전체 구조에서 하나의 layer를 나타내고 오른쪽 그림인 (b)는 이 layer들이 쌓여 전체 구조를 나타낸다. (a), (b)를 각각 나눠 따로 설명한다.

##### Single Layer

앞서 말했듯이 모델은 multiple hop 구조를 가진다고 했다. 전체 모델을 소개 전에 우선 하나의 layer에 대해서 먼저 설명한다. multiple hop 구조는 이 single layer가 여러개 쌓인 형태이므로 간단하다.

**Input memory representation**

우선 input값 중 $x_1,x_2,...,x_i$는 memory에 저장된다. 저장될 떄는 d-차원의 embedding vector로 변환된 후 저장된다. 따라서 ${x_i}$는 ${m_i}$로 storage에 저장된다. 이 때 embeddng vector를 만들기 위해 embedding matrix $A\in\mathbb{R}^{d\times V}$를 곱한다. 그리고 질문(query)도 embedding 된다. 이 때는 $A$와 같은 형태를 가지는 embedding matrix $B$를 곱한다. embedding 된 질문은 internal state $u$ 라 부른다. 다음으로는 질문과 문장들의 연관도를 구하기위해 각각의 $m_i$과 $u$를 각각 곱한 후 softmax를 취해서 계산한다. 이 값은 각 sentence와 query와의 연관성을 계산한 후 확률 벡터로 만들어준다고 생각하면된다. 즉 어떤 문장이 질문에 대해 연관성이 높은지를 계산한 값이다. 이 값을 확률 벡터 $p$라 부른다.

$$
p_i=\text{Softmax}(u^Tm_i)
$$

**Ouput memory representation**

위에서 각 ${x_i}$를 ${m_i}$로 만든 것처럼 똑같이 embedding한 output vector인 $c_i$들을 계산한다. 계산은 embedding matrix $C\in\mathbb{R}^{d\times V}$ 이 값을 output 값을 만들기 위해 사용된다. 그리고 최종 response를 만들기 위해 위에서 계산한 확률 벡터와 output vector를 가중평균한다. 이렇게 최종 response인 $o$를 만든다.

$$
o=\sum_ip_ic_i
$$

여기서 사용된 함수들은 smooth한 함수들이기 때문에 gardient를 계산하기 쉽다. 따라서 backpropagation을 통해 학습이 쉬워진다. 그리고 여기서 가중평균한 개념은 self attention과 유사한 개념이다.

**Generating the final prediction**

이제 최종 response를 통해 마지막 prediction값을 계산해야 한다. 이 떄 response와 계산하기 위해 질문 벡터(query vector)를 embedding 한 vector인 $u$를 사용한다. 두 벡터를 더한 후 가중치 행렬인 $W$를 곱한 후 Softmax 함수를 취해서 최종 prediction을 계산한다.

$$
\hat{a}=\text{Softmax}(W(o+u))
$$

여기까지하면 Single layer의 모델이 끝이난다. 총 4개의 parameter matrix $A,B,C,W$가 있고 학습의 경우 prediction 값인 $\hat{a}$와 실제 label $a$를 비교한 cross-entropy loss 함수를 사용하고 update는 SGD를 사용한다.

##### Multiple Layers

이제 위의 single layer를 확장해 전체 모델을 만들어 보자.위의 layer를 K개 쌓아서 만들면 된다. 이 때 몇 가지 특징이 있는데 다음과 같다.

* 첫 번째 layer를 제외한 layer의 질문(query) 벡터는 이전 layer의 output vector인 $o^k$와 query vector 인 $u^k$를 더한 값을 사용한다.

$$
u^{k+1} = u^k+o^k
$$

* 각 layer는 모두 다른 embedding matrix $A^k, C^k$를 사용한다. 하지만 parameter를 줄이기 위해 가중치를 공유할 수 있다 이는 밑에서 설명한다.

* 마지막 layer에서 계산하는 prediction은 다음과 같이 계산된다.

$$
\hat{a}=\text{Softmax}(Wu^{K+1})=\text{Softmax}(W(u^{K}+o^K))
$$

그리고 앞서 말했던 parameter를 줄이기 위한 방법으로 두 가지 방법이 사용될 수 있다.

1\. **Adjacent**

인접한 embedding matrix를 같은 weight를 사용하게 함으로써 paramter 수를 줄이는 방법이다. 즉 모든 $k$에 대해 아래의 식들을 만족한다.

* $A^{k+1}=C^k$ : 이전 layer의 $C$ matrix 와 해당 layer의 $A$ matrix는 같다.
* $W^T=C^K$ : prediction을 위한 matrix은 $W$는 마지막 layer의 $C$ matrix를 transpose한 것과 같다.
* $B=A^1$ : query를 embedding 하는 matrix인 $B$와 첫 layer의 $A$ matrix는 같다.

2\. **Layer-wise(RNN-like)**

여기서는 여러 matrix가 생기는 $A$와 $C$들이 각각 모두 같은 matrix를 사용하도록 한다. 즉 아래의 식을 만족한다.

$$
A^1=A^2=...=A^K
$$

$$
C^1=C^2=...=C^K
$$

그리고 이 경우에는 추가적인 linear mapping 함수인 $H$를 사용한다. 이 함수는 $u$ vector를 다음 값으로 넘길 때 사용된다.

$$
u^{k+1}=Hu^k+o^k
$$

여기까지가 전체 모델에 대한 설명이다. 전체적으로 기존 memory network의 모델인 menNN과 비슷한 형태를 취하고 있다. 가장 큰 차이점으로는 QA task에서 질문에 답하기 위해 모든 sentence를 필요로하지 않고 몇 개의 sentence만 필요로한다. 기존 모델인 menNN의 경우에는 이렇게 몇 개의 질문만을 사용하기 위해 supporting subset을 명시적으로 지정하고 학습 시 계속해서 따로 분리시키는데, 해당 모델에서는 이러한 과정없이 한번의 계산으로 질문과 유사한 문장들을 계산하기 때문에 End to End 한 모델이 될 수 있는 것이다.

그리고 학습에 사용된 몇 가지 세부적인 특징은 다음과 같다.

* Training data의 10%를 Validation data로 사용
* update 시 learning rate 는 0.01 사용, 매 25 에폭마다 절반으로 줄였고 총 100에폭동안 학습
* 가중치의 경우 평균 0, 표준편차 1인 정규 분포를 따르도록 했다. $\sim N(0,1)$
* Batch size 32
* 학습시 gradient 값의 $l_2 norm$이 40보다 커질 경우 더 커지지 못하고 40을 가지도록 함.
* K=3 으로 지정
* 파라미터를 줄이는 방법으로는 앞서 설명한 adjacent weight sharing 방법 사용

그리고 모델에 추가적으로 사용된 기법들에 대해서 알아보자.

**Sentence Representation**

문장의 경우 두 가지 representation 방식을 사용했다. 처음으로는 bag-of-words(BoW)를 사용했는데, 이 방식을 사용할 경우 단어들의 위치 정보를 반영하지 못하는 단점이 있다. 따라서 위치 값을 encoding해서 representation을 하였다.

$$
m_i = \sum_j l_j\otimes Ax_{ij}
$$

위 식에서 $l_j$가 위치 정보를 담은 값이다. 그리고 이 값은 아래의 수식 값을 가진다.

$$
l_{kj}=(1-j/J) - (k/d)(1-2j/J)
$$

이렇게 위치 정보를 embedding 하는 방법을 position encoding(PE)라 부른다.

**Temporal Encoding**

하나의 정보에 대해 두 가지 선택지가 나오는 경우가 있다. 예를 들어 특정 사람이 두 위치에 다녀왔고, 현재 위치를 물어보는 경우를 대비해서 temporal context의 개념을 사용했다. 이 방식은 memory vector인 $m_i$ 와 output vector인 $c_i$ 계산시 사용된다.

$$
m_i = \sum_j Ax_{ij}+T_A(i)
$$

$$
c_i=\sum_jCx_{ij}+T_C(i)
$$

여기서 사용된 $T_A$ 와 $T_C$는 temporal 정보를 가지는 matrix이고, 학습 시 같이 학습되는 가중치이다.

#### Result & Conclusion

이 모델도 결과는 따로 설명하지 않는다. 우선 이전의 모델과 비교하면 성능 자체는 약간 떨어지지만 End to End 로 학습한다는 것에 의미가 있고, 다른 task에 적용하기 쉽다는것이 해당 모델의 큰 장점이다. 이후 Dynamic Memory Network(DMN) 모델도 추가적으로 나왔으므로 이후에 같이 학습하면 도움이 될 것이다.


---

오역 및 잘못된 내용이 있을 수 있습니다. 잘못된 부분 혹은 이해가 잘 안되는 부분은 댓글 혹은 메일로 말씀해주시면 감사하겠습니다!
